{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31a53f9-a581-4146-9f08-e7dd5b151c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Evaluate Supply Chain Agent\n",
    "This notebook demonstrates how to:\n",
    "- Evaluate the agent with Mosaic AI Agent Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c2689b1-33f2-48f7-9c5c-156e369dd32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cluster Configuration\n",
    "This notebook was tested on the following Databricks cluster configuration:\n",
    "- **Databricks Runtime Version:** 16.4 LTS ML (includes Apache Spark 3.5.2, Scala 2.12)\n",
    "- **Single Node** \n",
    "    - Azure: Standard_DS4_v2 (28 GB Memory, 8 Cores)\n",
    "    - AWS: m5d.2xlarge (32 GB Memory, 8 Cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be1a545-8c29-49b3-8397-adfa5ee5e4bf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install requirements"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "%pip install -r ../requirements.txt --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e2ebb24-11d4-4b8c-ab7d-2b42b5ffcc21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4827460-0fe7-4ca1-a37a-dd718ae3ca86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks import agents\n",
    "\n",
    "# Connect to the Unity catalog model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "catalog = \"supply_chain_stress_test\"    # Change here\n",
    "schema = \"agents\"                       # Change here\n",
    "agent_name = \"supply_chain_agent\"       # Change here\n",
    "\n",
    "# Load the latest version of the model using pyfunc flavor\n",
    "agent = mlflow.pyfunc.load_model(f\"models:/{catalog}.{schema}.{agent_name}@latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac92b163-47a9-42f0-9751-5097253cf846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f55cc23c-90ab-4018-a8c7-f3f82b237d9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "# TODO: set WORKSPACE_URL manually if it cannot be inferred from the current notebook\n",
    "WORKSPACE_URL = None\n",
    "if WORKSPACE_URL is None:\n",
    "  workspace_url_hostname = get_context().browserHostName\n",
    "  assert workspace_url_hostname is not None, \"Unable to look up current workspace URL. This can happen if running against serverless compute. Manually set WORKSPACE_URL yourself above, or run this notebook against classic compute\"\n",
    "  WORKSPACE_URL = f\"https://{workspace_url_hostname}\"\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope = \"ryuta\"\n",
    "secret_key = \"token\"\n",
    "\n",
    "os.environ[\"HOST\"] = WORKSPACE_URL\n",
    "os.environ[\"TOKEN\"] = dbutils.secrets.get(scope=secret_scope, key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c41b9b7-163a-43cd-a0ed-e9a975669675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from supply_chain_agent import AGENT\n",
    "\n",
    "agent.predict({\"messages\": [{\"role\": \"user\", \"content\": \"What happens if T2_4 goes down and takes 6 weeks to recover? What should I do?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "113253a0-eb7c-4bf8-ab6c-d10f601d19b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics. Evaluate your agent with one of our [predefined LLM scorers](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f24623-27e4-4715-90ef-3d36da3592f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import mlflow.genai\n",
    "from mlflow.genai.judges import custom_prompt_judge\n",
    "from mlflow.entities import Trace, Feedback, SpanType\n",
    "from mlflow.genai.scorers import scorer\n",
    "from mlflow.genai.scorers import Guidelines, RelevanceToQuery, Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69eefaaf-364d-42d9-8377-8f06b0a53d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation dataset\n",
    "eval_data = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"List all downstream sites for the raw material supplied by T3_10, and include any related information about these sites.\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Tell me the demand for T1_5 and the inventory levels of all materials needed to produce T1_5.\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Tell me what happens if T2_8 is disrupted and requires 9 to recover. What should I do?\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"What happens if T2_4 goes down and takes 6 weeks to recover? What should I do?\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"There has been an incident at T3_15 and it will go down for the next 10 time units. Tell me what to do.\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab288365-4594-4e93-96b6-9a1603196d0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define evaluation scorers\n",
    "scorers = [\n",
    "    Guidelines(\n",
    "        name=\"response_length\",\n",
    "        guidelines=\"The response MUST be concise and to the point not longer than 500 words.\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        name=\"professional_tone\",\n",
    "        guidelines=\"The response MUST be in a professional tone.\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        name=\"includes_next_steps\",\n",
    "        guidelines=\"The response MUST end with a specific, actionable next step that includes a concrete timeline.\",\n",
    "    ),\n",
    "    RelevanceToQuery(),\n",
    "    Safety(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0772c3f-fa06-48ad-b9e0-ff3eef742150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "def evaluate_model(messages) -> dict:\n",
    "    return agent.predict({\"messages\": messages})\n",
    "  \n",
    "results = mlflow.genai.evaluate(\n",
    "    data=eval_data,\n",
    "    predict_fn=evaluate_model,\n",
    "    scorers=scorers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "254490f8-e5f5-4fb1-a598-8619b9fea2b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generated_traces = mlflow.search_traces(run_id=results.run_id)\n",
    "\n",
    "tool_usage_prompt = \"\"\"\n",
    "Evaluate the trace and determine if the right tool was used to answer the question.\n",
    "\n",
    "Question:\n",
    "{{question}}\n",
    "\n",
    "Tool spans to evaluate:\n",
    "{{spans}}\n",
    "\n",
    "Return ONLY a valid JSON object with exactly these keys:\n",
    "- \"rationale\": short explanation (<=80 words)\n",
    "- \"result\": one of [[pass]], [[partially_pass]], [[fail]]\n",
    "\n",
    "STRICT OUTPUT RULES:\n",
    "- Output a single JSON object.\n",
    "- No markdown, no code fences, no extra text before/after.\n",
    "- Example (copy the format exactly):\n",
    "{\"rationale\":\"...\", \"result\":\"pass\"}\n",
    "\"\"\".strip()\n",
    "\n",
    "@scorer\n",
    "def tool_usage(trace: Trace) -> Feedback:\n",
    "    \n",
    "    question = trace.search_spans(span_type=SpanType.AGENT)[0].inputs['messages'][0]['content']\n",
    "    tool_spans = trace.search_spans(span_type=SpanType.TOOL)\n",
    "    tool_spans_str = \"\\n\".join(\n",
    "        json.dumps(s.to_dict(), ensure_ascii=False) for s in tool_spans\n",
    "    )\n",
    "\n",
    "    judge = custom_prompt_judge(\n",
    "        name=\"tool_usage\",\n",
    "        prompt_template=tool_usage_prompt,\n",
    "        numeric_values={\n",
    "            \"pass\": 1,\n",
    "            \"partially_pass\": 0.5,\n",
    "            \"fail\": 0,\n",
    "        },\n",
    "    )\n",
    "    return judge(question=question, spans=tool_spans_str)\n",
    "\n",
    "@scorer\n",
    "def response_time(trace: Trace) -> Feedback:\n",
    "    \n",
    "    # Search particular span type from the trace\n",
    "    agent_span = trace.search_spans(span_type=SpanType.AGENT)[0]\n",
    "\n",
    "    response_time = (agent_span.end_time_ns - agent_span.start_time_ns) / 1e9 # second\n",
    "    max_duration = 120\n",
    "    if response_time <= max_duration:\n",
    "        return Feedback(\n",
    "            value=\"yes\",\n",
    "            rationale=f\"Response time {response_time:.2f}s is within the {max_duration}s limit.\"\n",
    "        )\n",
    "    else:\n",
    "        return Feedback(\n",
    "            value=\"no\",\n",
    "            rationale=f\"Response time {response_time:.2f}s exceeds the {max_duration}s limit.\"\n",
    "        )\n",
    "\n",
    "# Evaluate the scorer using the pre-generated traces from the prerequisite code block.\n",
    "trace_check_eval_results = mlflow.genai.evaluate(\n",
    "    data=generated_traces,\n",
    "    scorers=[response_time, tool_usage]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19dcf429-9d1f-4889-b541-af17c4549d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Assign `Production` alias to this version of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75f860dd-9a2b-4f41-b148-0466e255f499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "model_info = client.get_model_version_by_alias(f\"{catalog}.{schema}.{agent_name}\", \"latest\")\n",
    "client.set_registered_model_alias(f\"{catalog}.{schema}.{agent_name}\", \"production\", model_info.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8c30f92-d9b3-48fa-9994-d5702e7b86eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01_evaluate_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
