{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31a53f9-a581-4146-9f08-e7dd5b151c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Evaluate Supply Chain Agent\n",
    "This notebook demonstrates how to:\n",
    "- Evaluate the agent with Mosaic AI Agent Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c2689b1-33f2-48f7-9c5c-156e369dd32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cluster Configuration\n",
    "This notebook was tested on the following Databricks cluster configuration:\n",
    "- **Databricks Runtime Version:** 16.4 LTS ML (includes Apache Spark 3.5.2, Scala 2.12)\n",
    "- **Single Node** \n",
    "    - Azure: Standard_DS4_v2 (28 GB Memory, 8 Cores)\n",
    "    - AWS: m5d.2xlarge (32 GB Memory, 8 Cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be1a545-8c29-49b3-8397-adfa5ee5e4bf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install requirements"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "%pip install -r ../requirements.txt --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e2ebb24-11d4-4b8c-ab7d-2b42b5ffcc21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4827460-0fe7-4ca1-a37a-dd718ae3ca86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks import agents\n",
    "\n",
    "# Connect to the Unity catalog model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "catalog = \"supply_chain_stress_test\"    # Change here\n",
    "schema = \"agents\"                       # Change here\n",
    "agent_name = \"supply_chain_agent\"       # Change here\n",
    "\n",
    "# Load the latest version of the model using pyfunc flavor\n",
    "agent = mlflow.pyfunc.load_model(f\"models:/{catalog}.{schema}.{agent_name}@latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac92b163-47a9-42f0-9751-5097253cf846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f55cc23c-90ab-4018-a8c7-f3f82b237d9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "# TODO: set WORKSPACE_URL manually if it cannot be inferred from the current notebook\n",
    "WORKSPACE_URL = None\n",
    "if WORKSPACE_URL is None:\n",
    "  workspace_url_hostname = get_context().browserHostName\n",
    "  assert workspace_url_hostname is not None, \"Unable to look up current workspace URL. This can happen if running against serverless compute. Manually set WORKSPACE_URL yourself above, or run this notebook against classic compute\"\n",
    "  WORKSPACE_URL = f\"https://{workspace_url_hostname}\"\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope = \"ryuta\"\n",
    "secret_key = \"token\"\n",
    "\n",
    "os.environ[\"HOST\"] = WORKSPACE_URL\n",
    "os.environ[\"TOKEN\"] = dbutils.secrets.get(scope=secret_scope, key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c41b9b7-163a-43cd-a0ed-e9a975669675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from supply_chain_agent import AGENT\n",
    "\n",
    "agent.predict({\"messages\": [{\"role\": \"user\", \"content\": \"What happens if T2_4 goes down and takes 6 weeks to recover? What should I do?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "113253a0-eb7c-4bf8-ab6c-d10f601d19b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics. Evaluate your agent with one of our [predefined LLM scorers](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69eefaaf-364d-42d9-8377-8f06b0a53d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation dataset\n",
    "eval_data = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"List all downstream sites for the raw material supplied by T3_10, and include any related information about these sites.\"\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba9135b-2095-4057-b08c-51f5b06b2810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.genai\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Guidelines\n",
    "\n",
    "# Define evaluation scorers\n",
    "scorers = [\n",
    "    RelevanceToQuery(),\n",
    "    Guidelines(\n",
    "        guidelines=\"The right tool was used to answer the question.\",\n",
    "        name=\"tool_usage\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        guidelines=\"Response must not be longer than 500 words.\",\n",
    "        name=\"response_length\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0772c3f-fa06-48ad-b9e0-ff3eef742150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "def evaluate_model(messages) -> dict:\n",
    "    return agent.predict({\"messages\": messages})\n",
    "  \n",
    "results = mlflow.genai.evaluate(\n",
    "    data=eval_data,\n",
    "    predict_fn=evaluate_model,\n",
    "    scorers=scorers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19dcf429-9d1f-4889-b541-af17c4549d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Assign `Production` alias to this version of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75f860dd-9a2b-4f41-b148-0466e255f499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "model_info = client.get_model_version_by_alias(f\"{catalog}.{schema}.{agent_name}\", \"latest\")\n",
    "client.set_registered_model_alias(f\"{catalog}.{schema}.{agent_name}\", \"Production\", model_info.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8c30f92-d9b3-48fa-9994-d5702e7b86eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01_evaluate_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
