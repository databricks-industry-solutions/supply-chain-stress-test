{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e31a53f9-a581-4146-9f08-e7dd5b151c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Build and Deploy Supply Chain Agent\n",
    "This notebook demonstrates how to:\n",
    "- Author a supply chain agent that uses data access, data analysis and optimization tools.\n",
    "- Manually test the agent's output.\n",
    "- Evaluate the agent with Mosaic AI Agent Evaluation.\n",
    "- Log and deploy the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c2689b1-33f2-48f7-9c5c-156e369dd32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cluster Configuration\n",
    "This notebook was tested on the following Databricks cluster configuration:\n",
    "- **Databricks Runtime Version:** 16.4 LTS ML (includes Apache Spark 3.5.2, Scala 2.12)\n",
    "- **Single Node** \n",
    "    - Azure: Standard_DS4_v2 (28 GB Memory, 8 Cores)\n",
    "    - AWS: m5d.2xlarge (32 GB Memory, 8 Cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be1a545-8c29-49b3-8397-adfa5ee5e4bf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install requirements"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "%pip install -r ../requirements.txt --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7887a82-9937-4dba-82e1-2459f803042c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the agent in code\n",
    "Below we define our agent code in a single cell, enabling us to easily write it to a local Python file for subsequent logging and deployment using the `%%writefile` magic command.\n",
    "\n",
    "For more examples of tools to add to your agent, see [docs](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/agent-tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c98451d-b9d3-4103-bffd-4c6c2a71c8b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile supply_chain_agent.py\n",
    "from typing import Any, Optional, Sequence, Union\n",
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from databricks_langchain import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.models import ModelConfig\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "import random, string, math\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import pyomo.environ as pyo\n",
    "import scripts.utils as utils\n",
    "\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT = \"gpt-5\"\n",
    "\n",
    "config = {\n",
    "    \"endpoint_name\": LLM_ENDPOINT,\n",
    "    \"catalog\": \"supply_chain_stress_test\",\n",
    "    \"database\": \"data\",\n",
    "    \"volume\": \"operational\",\n",
    "    \"temperature\": 0.01,\n",
    "    \"max_tokens\": 10000,\n",
    "    \"system_prompt\": \"\"\"\n",
    "    \"You are a helpful assistant that answers questions about a supply chain network. Questions outside this topic are considered irrelevant. You use a set of tools to provide answers, and if needed, you ask the user follow up questions to clarify their request. You may need to execute multiple tools in sequence to build up the final answer. When you receive a request, first plan the steps carefully and then execute.\n",
    "\n",
    "    When interpreting the output of the optimization tool, make use of the following definiiotns of the parameters, decision variables and metric.\n",
    "\n",
    "    - Below are the definitions of the important metrics:\n",
    "    Metrics               | What it represents\n",
    "    TTR                   | Stands for time to recover. Recovery time for a node or group after a disruption.               |\n",
    "    TTS                   | Stands for time to survive. TTS indicates how long the network can meet demand with no loss.    |\n",
    "\n",
    "    - Below are the definitions of the model parameters:\n",
    "    Parameters            | What it represents                                                                                      | \n",
    "    tier1 / tier2 / tier3 | Lists of node IDs in each tier.                                                                         |\n",
    "    edges                 | Directed links `(source, target)` showing which node supplies which.                                    |\n",
    "    material_type         | List of all material types.                                                                             |\n",
    "    supplier_material_type| Material type each supplier produces and supplies.                                                      |\n",
    "    f                     | Profit margin for each Tier 1 node's finished product.                                                  |\n",
    "    s                     | On-hand inventory units at every node.                                                                  |\n",
    "    d                     | Demand per time unit for Tier 1 products.                                                               |\n",
    "    c                     | Production capacity per time unit at each node.                                                         |\n",
    "    r                     | Number of material types (k) required to make one unit of node j.                                       |\n",
    "    N_minus               | For each node j (Tier 1 or 2), the set of material types it requires.                                   |\n",
    "    N_plus                | For each supplier i (Tier 2 or 3), the set of downstream nodes j it feeds.                              |\n",
    "    P                     | For each (j, material_part) pair, a list of upstream suppliers i that provides it (multi-sourcing view).|\n",
    "    \n",
    "    - Below are the definitions of decision variables:\n",
    "    Decision Variables    | What it represents                                                                                 | \n",
    "    l                     | Production volume lost of the product of the node.                                                 |\n",
    "    u                     | Total production volume of the node during the ttr.                                                |\n",
    "    y                     | Allocation of upstream node to downsteam node during the ttr.                                      |\n",
    "    \n",
    "    Report the profit loss during the recovery period. When giving recommendations, compare the optimized network with and without the disruption and base them on differences in the decision variables. Include detailed action plans, a summary of the best actions for this scenario, and precise numbers whenever possible. Finally, the users of this tool are buisness analysts, so keep the language simple and avoid technical terms.\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/agent-tool\n",
    "###############################################################################\n",
    "@tool\n",
    "def data_access_tool(\n",
    "    catalog: str = config[\"catalog\"],\n",
    "    database: str = config[\"database\"],\n",
    "    volume: str = config[\"volume\"],\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Accesses supply chain dataset stored in the specified Unity Catalog Volume and returns the data. \n",
    "\n",
    "    Parameters:\n",
    "    catalog (str): Catalog name for Unity Catalog.\n",
    "    database (str): Database name in Unity Catalog.\n",
    "    volume (str): Volume name in Unity Catalog.\n",
    "    \n",
    "    Returns:\n",
    "    str: Dataset results.\n",
    "    \"\"\"    \n",
    "    # Get the operational data from Unity Catalog Volume\n",
    "    w = WorkspaceClient(host=os.getenv(\"HOST\"), token=os.getenv(\"TOKEN\"))\n",
    "    path = f'/Volumes/{catalog}/{database}/{volume}/dataset_small.json'\n",
    "    resp = w.files.download(path)\n",
    "    with resp.contents as fh:\n",
    "        dataset = json.load(fh)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "@tool\n",
    "def optimization_tool(\n",
    "    disrupted: list[str],\n",
    "    ttr: float,\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Runs optimization algorithms for a given disrupted scenario and returns the results as a string. This function first solves the optimization problem without considering the disruption, and then solves the problem with the disruption. The function returns a string containing the results of both optimizations.\n",
    "\n",
    "    Parameters:\n",
    "    disrupted (list[str]): List of disrupted nodes in the scenario.\n",
    "    ttr (float): Time to recover (TTR) for the disruption scenario.\n",
    "    \n",
    "    Returns:\n",
    "    str: A string representation of the optimization results.\n",
    "    \"\"\"    \n",
    "    # Get the operational data from Unity Catalog Volume\n",
    "    dataset = data_access_tool.func()\n",
    "\n",
    "    # Solve the TTR model without distruption\n",
    "    df_normal = utils.build_and_solve_ttr(dataset, [], ttr, True)\n",
    "    model = df_normal[\"model\"].values[0]\n",
    "    records_normal = []\n",
    "    for v in model.component_data_objects(ctype=pyo.Var, active=True):\n",
    "        idx  = v.index()\n",
    "        record  = {\n",
    "            \"var_name\"  : v.parent_component().name,\n",
    "            \"index\"     : idx,\n",
    "            \"value\"     : pyo.value(v),\n",
    "        }\n",
    "        records_normal.append(record)\n",
    "    \n",
    "    # Solve the TTR model with distruption\n",
    "    df_distrupted  = utils.build_and_solve_ttr(dataset, disrupted, ttr, True)\n",
    "    model = df_distrupted[\"model\"].values[0]\n",
    "    records_distrupted = []\n",
    "    for v in model.component_data_objects(ctype=pyo.Var, active=True):\n",
    "        idx  = v.index()\n",
    "        record  = {\n",
    "            \"var_name\"  : v.parent_component().name,\n",
    "            \"index\"     : idx,\n",
    "            \"value\"     : pyo.value(v),\n",
    "        }\n",
    "        records_distrupted.append(record)\n",
    "\n",
    "    df_distrupted = df_distrupted.drop([\"model\"], axis=1)\n",
    "    df_distrupted[\"optimized_network_without_disruption\"] = str(records_normal)\n",
    "    df_distrupted[\"optimized_network_with_disruption\"] = str(records_distrupted)\n",
    "\n",
    "    # Solve the TTS model with distruption\n",
    "    df_tts = utils.build_and_solve_tts(dataset, disrupted, False)\n",
    "    df_distrupted[\"tts\"] = df_tts[\"tts\"].values[0]\n",
    "    \n",
    "    # Convert the result to string\n",
    "    row_str = \",\".join(f\"{k}={v}\" for k, v in df_distrupted.iloc[0].astype(str).items())\n",
    "\n",
    "    return row_str\n",
    "\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    agent_prompt: Optional[str] = None,\n",
    ") -> CompiledGraph:\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    def routing_logic(state: ChatAgentState):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    if agent_prompt:\n",
    "        system_message = {\"role\": \"system\", \"content\": agent_prompt}\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [system_message] + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        routing_logic,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "class SupplyChainAgent(ChatAgent):\n",
    "    def __init__(self, config, tools):\n",
    "        # Load config\n",
    "        # When this agent is deployed to Model Serving, the configuration loaded here is replaced with the config passed to mlflow.pyfunc.log_model(model_config=...)\n",
    "        self.config = ModelConfig(development_config=config)\n",
    "        self.tools = tools\n",
    "        self.agent = self._build_agent_from_config()\n",
    "\n",
    "    def _build_agent_from_config(self):\n",
    "        llm = ChatDatabricks(\n",
    "            endpoint=self.config.get(\"endpoint_name\"),\n",
    "            #temperature=self.config.get(\"temperature\"),\n",
    "            max_tokens=self.config.get(\"max_tokens\"),\n",
    "        )\n",
    "        agent = create_tool_calling_agent(\n",
    "            llm,\n",
    "            tools=self.tools,\n",
    "            agent_prompt=self.config.get(\"system_prompt\"),\n",
    "        )\n",
    "        return agent\n",
    "\n",
    "    @mlflow.trace(name=\"SupplyChainAgent\", span_type=mlflow.entities.SpanType.AGENT)\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        # ChatAgent has a built-in helper method to help convert framework-specific messages, like langchain BaseMessage to a python dictionary\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        output = self.agent.invoke(request)\n",
    "        # Here 'output' is already a ChatAgentResponse, but to make the ChatAgent signature explicit for this demonstration we are returning a new instance\n",
    "        return ChatAgentResponse(**output)\n",
    "    \n",
    "tools = [data_access_tool, optimization_tool]\n",
    "\n",
    "AGENT = SupplyChainAgent(config, tools)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac92b163-47a9-42f0-9751-5097253cf846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cea98c99-9b63-443f-874a-5605db8e18f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64fb8387-6e21-4a42-af61-3910b21d3877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define enviroment variables for the agent to use to authenticate itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f55cc23c-90ab-4018-a8c7-f3f82b237d9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "user = spark.sql('select current_user() as user').collect()[0]['user'] # User email address\n",
    "\n",
    "# TODO: set WORKSPACE_URL manually if it cannot be inferred from the current notebook\n",
    "WORKSPACE_URL = None\n",
    "if WORKSPACE_URL is None:\n",
    "  workspace_url_hostname = get_context().browserHostName\n",
    "  assert workspace_url_hostname is not None, \"Unable to look up current workspace URL. This can happen if running against serverless compute. Manually set WORKSPACE_URL yourself above, or run this notebook against classic compute\"\n",
    "  WORKSPACE_URL = f\"https://{workspace_url_hostname}\"\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope = \"ryuta\"\n",
    "secret_key = \"token\"\n",
    "\n",
    "os.environ[\"HOST\"] = WORKSPACE_URL\n",
    "os.environ[\"TOKEN\"] = dbutils.secrets.get(scope=secret_scope, key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38880f13-433e-453d-b0ab-b8ba65877771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from supply_chain_agent import AGENT\n",
    "\n",
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"List all downstream sites for the raw material supplied by T3_10, and include any related information about these sites. Visualize the results clearly.\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c41b9b7-163a-43cd-a0ed-e9a975669675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me what happens if T2_8 is disrupted and requires 9 weeks to recover. What should I do?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2903dcf7-ec02-4a78-90f7-b55642d6dd8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the `agent` as an MLflow model\n",
    "Log the agent as code from the `supply_chain_agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94dd7ff6-6fbd-4de3-a8c6-3a11465dba8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from supply_chain_agent import LLM_ENDPOINT, config, tools\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT)]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "code_path = os.getcwd().replace(\"agent\", \"scripts\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=\"supply_chain_agent.py\",\n",
    "        name=\"agent\",\n",
    "        model_config=config,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"langchain\",\n",
    "            \"langgraph==0.3.4\",\n",
    "            \"databricks-langchain\",\n",
    "            \"unitycatalog-langchain[databricks]\",\n",
    "            \"pydantic\",\n",
    "            \"-r ../requirements.txt\",\n",
    "        ],\n",
    "        code_paths=[code_path],\n",
    "        input_example={\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Tell me what happens if T2_8 is disrupted and requires 9 to recover to its normal state and what to do.\"}]\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "113253a0-eb7c-4bf8-ab6c-d10f601d19b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics.\n",
    "\n",
    "Evaluate your agent with one of our [predefined LLM scorers](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69eefaaf-364d-42d9-8377-8f06b0a53d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Why should I use databricks for forecasting?\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input}),\n",
    "    scorers=[RelevanceToQuery(), Safety()], # add more scorers here if they're applicable\n",
    ")\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19dcf429-9d1f-4889-b541-af17c4549d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the agent to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bfb7239-9789-4855-b704-456d69da7078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks import agents\n",
    "\n",
    "# Connect to the Unity catalog model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "catalog = \"supply_chain_stress_test\"    # Change here\n",
    "schema = \"agents\"                       # Change here\n",
    "agent_name = \"supply_chain_agent\"       # Change here\n",
    "\n",
    "# Make sure that the catalog, the schema and the volume exist\n",
    "_ = spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog}\") \n",
    "_ = spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\") \n",
    "\n",
    "MODEL_NAME = f\"{catalog}.{schema}.{agent_name}\"\n",
    "\n",
    "# Register to Unity catalog\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=model_info.model_uri, name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c04519a-c43d-47f5-914f-96837a7aaaf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5227974b-450d-4efb-a60c-123d776d9bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Deploy to enable the review app and create an API endpoint\n",
    "deployment_info = agents.deploy(\n",
    "    MODEL_NAME, \n",
    "    uc_registered_model_info.version,\n",
    "    environment_vars={\n",
    "        \"HOST\": f\"{WORKSPACE_URL}\",\n",
    "        \"TOKEN\": f\"{{{{secrets/{secret_scope}/{secret_key}}}}}\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8c30f92-d9b3-48fa-9994-d5702e7b86eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See [docs](https://learn.microsoft.com/azure/databricks/generative-ai/deploy-agent) for details"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00_build_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
