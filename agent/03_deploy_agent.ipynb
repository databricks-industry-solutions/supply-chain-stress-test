{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31a53f9-a581-4146-9f08-e7dd5b151c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploy Supply Chain Agent\n",
    "This notebook demonstrates how to deploy the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c2689b1-33f2-48f7-9c5c-156e369dd32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cluster Configuration\n",
    "This notebook was tested on the following Databricks cluster configuration:\n",
    "- **Databricks Runtime Version:** 16.4 LTS ML (includes Apache Spark 3.5.2, Scala 2.12)\n",
    "- **Single Node** \n",
    "    - Azure: Standard_DS4_v2 (28 GB Memory, 8 Cores)\n",
    "    - AWS: m5d.2xlarge (32 GB Memory, 8 Cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be1a545-8c29-49b3-8397-adfa5ee5e4bf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install requirements"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944608d0-3158-4672-baeb-6b2e71fdc370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2fad710-f592-4818-9337-6169d8e0304c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "client = MlflowClient()\n",
    "# Connect to the Unity catalog model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "catalog = \"supply_chain_stress_test\"    # Change here\n",
    "schema = \"agents\"                       # Change here\n",
    "agent_name = \"supply_chain_agent\"       # Change here\n",
    "model_info = client.get_model_version_by_alias(f\"{catalog}.{schema}.{agent_name}\", \"production\")\n",
    "\n",
    "user_email = spark.sql('select current_user() as user').collect()[0]['user']  # User email address\n",
    "first_name = user_email.split('.')[0]                                         # User first name\n",
    "\n",
    "mlflow.set_experiment(f\"/Users/{user_email}/supply-chain-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c04519a-c43d-47f5-914f-96837a7aaaf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "976a927f-87fc-4b77-b2ab-d3cf27d0ad3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "# TODO: set WORKSPACE_URL manually if it cannot be inferred from the current notebook\n",
    "WORKSPACE_URL = None\n",
    "if WORKSPACE_URL is None:\n",
    "  workspace_url_hostname = get_context().browserHostName\n",
    "  assert workspace_url_hostname is not None, \"Unable to look up current workspace URL. This can happen if running against serverless compute. Manually set WORKSPACE_URL yourself above, or run this notebook against classic compute\"\n",
    "  WORKSPACE_URL = f\"https://{workspace_url_hostname}\"\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope = first_name\n",
    "secret_key = \"token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5227974b-450d-4efb-a60c-123d776d9bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Deploy to enable the review app and create an API endpoint\n",
    "deployment_info = agents.deploy(\n",
    "    f\"{catalog}.{schema}.{agent_name}\", \n",
    "    model_info.version,\n",
    "    environment_vars={\n",
    "        \"HOST\": f\"{WORKSPACE_URL}\",\n",
    "        \"TOKEN\": f\"{{{{secrets/{secret_scope}/{secret_key}}}}}\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8c30f92-d9b3-48fa-9994-d5702e7b86eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See [docs](https://learn.microsoft.com/azure/databricks/generative-ai/deploy-agent) for details"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03_deploy_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
